{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      "customerID          7043 non-null object\n",
      "gender              7043 non-null object\n",
      "SeniorCitizen       7043 non-null int64\n",
      "Partner             7043 non-null object\n",
      "Dependents          7043 non-null object\n",
      "tenure              7043 non-null int64\n",
      "PhoneService        7043 non-null object\n",
      "MultipleLines       7043 non-null object\n",
      "InternetService     7043 non-null object\n",
      "OnlineSecurity      7043 non-null object\n",
      "OnlineBackup        7043 non-null object\n",
      "DeviceProtection    7043 non-null object\n",
      "TechSupport         7043 non-null object\n",
      "StreamingTV         7043 non-null object\n",
      "StreamingMovies     7043 non-null object\n",
      "Contract            7043 non-null object\n",
      "PaperlessBilling    7043 non-null object\n",
      "PaymentMethod       7043 non-null object\n",
      "MonthlyCharges      7043 non-null float64\n",
      "TotalCharges        7043 non-null object\n",
      "Churn               7043 non-null object\n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('E:\\SnehaWork\\AIProject\\Dataset\\Customer-Churn.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5174 1869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['customerID',\n",
       " 'gender',\n",
       " 'SeniorCitizen',\n",
       " 'Partner',\n",
       " 'Dependents',\n",
       " 'tenure',\n",
       " 'PhoneService',\n",
       " 'MultipleLines',\n",
       " 'InternetService',\n",
       " 'OnlineSecurity',\n",
       " 'OnlineBackup',\n",
       " 'DeviceProtection',\n",
       " 'TechSupport',\n",
       " 'StreamingTV',\n",
       " 'StreamingMovies',\n",
       " 'Contract',\n",
       " 'PaperlessBilling',\n",
       " 'PaymentMethod',\n",
       " 'MonthlyCharges',\n",
       " 'TotalCharges',\n",
       " 'Churn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Churned = df[df.Churn == 'Yes']\n",
    "NonChurned = df[df.Churn == 'No']\n",
    "\n",
    "number_of_Churned = len(Churned)\n",
    "number_of_NonChurned = len(NonChurned)\n",
    "\n",
    "Churned_percentage = round((number_of_Churned / (number_of_Churned + number_of_NonChurned)) * 100, 2)\n",
    "valid_percentage = round((number_of_NonChurned / (number_of_Churned + number_of_NonChurned)) * 100, 2)\n",
    "print(number_of_NonChurned,number_of_Churned)\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes\n",
    "#count yes and no on base data, train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('customerID',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#error='coerce' ignores the errors. Conversion for all except for error values i.e. empty spaces. \n",
    "#.isnull() gives columns which have empty spaces\n",
    "#shows the data which has TotalCharges as null. Good to drop these\n",
    "\n",
    "df[pd.to_numeric(df.TotalCharges,errors='coerce').isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows with TotalCharges as null\n",
    "\n",
    "df1 = df[df.TotalCharges!=' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df1.TotalCharges = pd.to_numeric(df1.TotalCharges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4263: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  method=method,\n"
     ]
    }
   ],
   "source": [
    "df1.replace('No internet service','No',inplace=True)\n",
    "df1.replace('No phone service','No',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6786: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "#replace Yes/No to 1/0 since ML doesn't understand text\n",
    "\n",
    "yes_no_columns = ['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',\n",
    "                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']\n",
    "\n",
    "for col in yes_no_columns:\n",
    "    df1[col].replace({'Yes': 1,'No': 0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['gender'].replace({'Male':1,'Female':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding for multiclass i.e. InternetService, Contract, PaymentMethod\n",
    "\n",
    "multiclass_col=['InternetService', 'Contract', 'PaymentMethod']\n",
    "df1 = pd.get_dummies(data=df1,columns=multiclass_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the values between 1 and 0 for below\n",
    "cols_to_scale = ['tenure','MonthlyCharges','TotalCharges']\n",
    "\n",
    "#MinMaxScaler scales the data between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df1[cols_to_scale] = scaler.fit_transform(df1[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_col_values(df):\n",
    "    for column in df:\n",
    "        print(f'{column} : {df[column].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender : [0 1]\n",
      "SeniorCitizen : [0 1]\n",
      "Partner : [1 0]\n",
      "Dependents : [0 1]\n",
      "tenure : [0.         0.46478873 0.01408451 0.61971831 0.09859155 0.29577465\n",
      " 0.12676056 0.38028169 0.85915493 0.16901408 0.21126761 0.8028169\n",
      " 0.67605634 0.33802817 0.95774648 0.71830986 0.98591549 0.28169014\n",
      " 0.15492958 0.4084507  0.64788732 1.         0.22535211 0.36619718\n",
      " 0.05633803 0.63380282 0.14084507 0.97183099 0.87323944 0.5915493\n",
      " 0.1971831  0.83098592 0.23943662 0.91549296 0.11267606 0.02816901\n",
      " 0.42253521 0.69014085 0.88732394 0.77464789 0.08450704 0.57746479\n",
      " 0.47887324 0.66197183 0.3943662  0.90140845 0.52112676 0.94366197\n",
      " 0.43661972 0.76056338 0.50704225 0.49295775 0.56338028 0.07042254\n",
      " 0.04225352 0.45070423 0.92957746 0.30985915 0.78873239 0.84507042\n",
      " 0.18309859 0.26760563 0.73239437 0.54929577 0.81690141 0.32394366\n",
      " 0.6056338  0.25352113 0.74647887 0.70422535 0.35211268 0.53521127]\n",
      "PhoneService : [0 1]\n",
      "MultipleLines : [0 1]\n",
      "OnlineSecurity : [0 1]\n",
      "OnlineBackup : [1 0]\n",
      "DeviceProtection : [0 1]\n",
      "TechSupport : [0 1]\n",
      "StreamingTV : [0 1]\n",
      "StreamingMovies : [0 1]\n",
      "PaperlessBilling : [1 0]\n",
      "MonthlyCharges : [0.11542289 0.38507463 0.35422886 ... 0.44626866 0.25820896 0.60149254]\n",
      "TotalCharges : [0.0012751  0.21586661 0.01031041 ... 0.03780868 0.03321025 0.78764136]\n",
      "Churn : [0 1]\n",
      "InternetService_DSL : [1 0]\n",
      "InternetService_Fiber optic : [0 1]\n",
      "InternetService_No : [0 1]\n",
      "Contract_Month-to-month : [1 0]\n",
      "Contract_One year : [0 1]\n",
      "Contract_Two year : [0 1]\n",
      "PaymentMethod_Bank transfer (automatic) : [0 1]\n",
      "PaymentMethod_Credit card (automatic) : [0 1]\n",
      "PaymentMethod_Electronic check : [1 0]\n",
      "PaymentMethod_Mailed check : [0 1]\n"
     ]
    }
   ],
   "source": [
    "print_unique_col_values(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5163\n",
       "1    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop churn \n",
    "x = df1.drop('Churn',axis=1)  #check axis=0/1\n",
    "y = df1['Churn']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test and train split. 80% for training and 20% for test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3329\n",
       "1    1171\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    835\n",
       "1    290\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    999\n",
       "1    408\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_cols = len(x.columns)\n",
    "num_of_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values.reshape(X_train.shape[0],num_of_cols, 1).astype('float32') \n",
    "X_test=X_test.values.reshape(X_test.shape[0],num_of_cols, 1).astype('float32')\n",
    "X_val=X_val.values.reshape(X_val.shape[0],num_of_cols, 1).astype('float32')\n",
    "\n",
    "#sometimes works as X_val.values.reshape(X_val.shape[0],26, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1407, 26, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1125, 26, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 26, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 1125 samples\n",
      "Epoch 1/70\n",
      " 375/4500 [=>............................] - ETA: 27s - loss: 0.6710 - accuracy: 0.7920WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.128474). Check your callbacks.\n",
      "4500/4500 [==============================] - 4s 923us/sample - loss: 0.6008 - accuracy: 0.7398 - val_loss: 0.5612 - val_accuracy: 0.7422\n",
      "Epoch 2/70\n",
      "4500/4500 [==============================] - 1s 246us/sample - loss: 0.5563 - accuracy: 0.7398 - val_loss: 0.5390 - val_accuracy: 0.7422\n",
      "Epoch 3/70\n",
      "4500/4500 [==============================] - 1s 231us/sample - loss: 0.5285 - accuracy: 0.7398 - val_loss: 0.5074 - val_accuracy: 0.7422\n",
      "Epoch 4/70\n",
      "4500/4500 [==============================] - 1s 226us/sample - loss: 0.4905 - accuracy: 0.7420 - val_loss: 0.4691 - val_accuracy: 0.7609\n",
      "Epoch 5/70\n",
      "4500/4500 [==============================] - 1s 229us/sample - loss: 0.4577 - accuracy: 0.7744 - val_loss: 0.4496 - val_accuracy: 0.7884\n",
      "Epoch 6/70\n",
      "4500/4500 [==============================] - 1s 255us/sample - loss: 0.4416 - accuracy: 0.7900 - val_loss: 0.4377 - val_accuracy: 0.7911\n",
      "Epoch 7/70\n",
      "4500/4500 [==============================] - 1s 249us/sample - loss: 0.4320 - accuracy: 0.7909 - val_loss: 0.4328 - val_accuracy: 0.7956\n",
      "Epoch 8/70\n",
      "4500/4500 [==============================] - 1s 226us/sample - loss: 0.4278 - accuracy: 0.7927 - val_loss: 0.4282 - val_accuracy: 0.7911\n",
      "Epoch 9/70\n",
      "4500/4500 [==============================] - 1s 204us/sample - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.4268 - val_accuracy: 0.7920\n",
      "Epoch 10/70\n",
      "4500/4500 [==============================] - 1s 205us/sample - loss: 0.4204 - accuracy: 0.7973 - val_loss: 0.4265 - val_accuracy: 0.7929\n",
      "Epoch 11/70\n",
      "4500/4500 [==============================] - 1s 227us/sample - loss: 0.4236 - accuracy: 0.7953 - val_loss: 0.4255 - val_accuracy: 0.7920\n",
      "Epoch 12/70\n",
      "4500/4500 [==============================] - 1s 238us/sample - loss: 0.4178 - accuracy: 0.7989 - val_loss: 0.4197 - val_accuracy: 0.7938\n",
      "Epoch 13/70\n",
      "4500/4500 [==============================] - 1s 225us/sample - loss: 0.4149 - accuracy: 0.7993 - val_loss: 0.4188 - val_accuracy: 0.7920\n",
      "Epoch 14/70\n",
      "4500/4500 [==============================] - 1s 231us/sample - loss: 0.4136 - accuracy: 0.8033 - val_loss: 0.4179 - val_accuracy: 0.7929\n",
      "Epoch 15/70\n",
      "4500/4500 [==============================] - 1s 219us/sample - loss: 0.4122 - accuracy: 0.8020 - val_loss: 0.4152 - val_accuracy: 0.7964\n",
      "Epoch 16/70\n",
      "4500/4500 [==============================] - 1s 224us/sample - loss: 0.4107 - accuracy: 0.8020 - val_loss: 0.4148 - val_accuracy: 0.7964\n",
      "Epoch 17/70\n",
      "4500/4500 [==============================] - 1s 242us/sample - loss: 0.4121 - accuracy: 0.8016 - val_loss: 0.4151 - val_accuracy: 0.7991\n",
      "Epoch 18/70\n",
      "4500/4500 [==============================] - 1s 243us/sample - loss: 0.4104 - accuracy: 0.8084 - val_loss: 0.4135 - val_accuracy: 0.7964\n",
      "Epoch 19/70\n",
      "4500/4500 [==============================] - 1s 224us/sample - loss: 0.4109 - accuracy: 0.8027 - val_loss: 0.4128 - val_accuracy: 0.7947\n",
      "Epoch 20/70\n",
      "4500/4500 [==============================] - 1s 221us/sample - loss: 0.4089 - accuracy: 0.8078 - val_loss: 0.4147 - val_accuracy: 0.8027\n",
      "Epoch 21/70\n",
      "4500/4500 [==============================] - 1s 224us/sample - loss: 0.4081 - accuracy: 0.8036 - val_loss: 0.4111 - val_accuracy: 0.7991\n",
      "Epoch 22/70\n",
      "4500/4500 [==============================] - 1s 246us/sample - loss: 0.4040 - accuracy: 0.8069 - val_loss: 0.4110 - val_accuracy: 0.8036\n",
      "Epoch 23/70\n",
      "4500/4500 [==============================] - 1s 235us/sample - loss: 0.4048 - accuracy: 0.8084 - val_loss: 0.4202 - val_accuracy: 0.7982\n",
      "Epoch 24/70\n",
      "4500/4500 [==============================] - 1s 229us/sample - loss: 0.4052 - accuracy: 0.8071 - val_loss: 0.4112 - val_accuracy: 0.8053\n",
      "Epoch 25/70\n",
      "4500/4500 [==============================] - 1s 224us/sample - loss: 0.4017 - accuracy: 0.8093 - val_loss: 0.4101 - val_accuracy: 0.8053\n",
      "Epoch 26/70\n",
      "4500/4500 [==============================] - 1s 212us/sample - loss: 0.3996 - accuracy: 0.8093 - val_loss: 0.4103 - val_accuracy: 0.8018\n",
      "Epoch 27/70\n",
      "4500/4500 [==============================] - 1s 219us/sample - loss: 0.4009 - accuracy: 0.8093 - val_loss: 0.4170 - val_accuracy: 0.7973\n",
      "Epoch 28/70\n",
      "4500/4500 [==============================] - 1s 228us/sample - loss: 0.4012 - accuracy: 0.8113 - val_loss: 0.4100 - val_accuracy: 0.7982\n",
      "Epoch 29/70\n",
      "4500/4500 [==============================] - 1s 232us/sample - loss: 0.3975 - accuracy: 0.8122 - val_loss: 0.4119 - val_accuracy: 0.8071\n",
      "Epoch 30/70\n",
      "4500/4500 [==============================] - 1s 233us/sample - loss: 0.3990 - accuracy: 0.8131 - val_loss: 0.4161 - val_accuracy: 0.8027\n",
      "Epoch 31/70\n",
      "4500/4500 [==============================] - 1s 220us/sample - loss: 0.3976 - accuracy: 0.8124 - val_loss: 0.4115 - val_accuracy: 0.8044\n",
      "Epoch 32/70\n",
      "4500/4500 [==============================] - 1s 222us/sample - loss: 0.3965 - accuracy: 0.8113 - val_loss: 0.4106 - val_accuracy: 0.7982\n",
      "Epoch 33/70\n",
      "4500/4500 [==============================] - 1s 242us/sample - loss: 0.3964 - accuracy: 0.8136 - val_loss: 0.4087 - val_accuracy: 0.8036\n",
      "Epoch 34/70\n",
      "4500/4500 [==============================] - 1s 245us/sample - loss: 0.3956 - accuracy: 0.8116 - val_loss: 0.4084 - val_accuracy: 0.8018\n",
      "Epoch 35/70\n",
      "4500/4500 [==============================] - 1s 247us/sample - loss: 0.3938 - accuracy: 0.8133 - val_loss: 0.4090 - val_accuracy: 0.8027\n",
      "Epoch 36/70\n",
      "4500/4500 [==============================] - 1s 220us/sample - loss: 0.3947 - accuracy: 0.8156 - val_loss: 0.4099 - val_accuracy: 0.8062\n",
      "Epoch 37/70\n",
      "4500/4500 [==============================] - 1s 219us/sample - loss: 0.3936 - accuracy: 0.8136 - val_loss: 0.4080 - val_accuracy: 0.8053\n",
      "Epoch 38/70\n",
      "4500/4500 [==============================] - 1s 220us/sample - loss: 0.3919 - accuracy: 0.8131 - val_loss: 0.4090 - val_accuracy: 0.8044\n",
      "Epoch 39/70\n",
      "4500/4500 [==============================] - 1s 227us/sample - loss: 0.3908 - accuracy: 0.8144 - val_loss: 0.4106 - val_accuracy: 0.8089\n",
      "Epoch 40/70\n",
      "4500/4500 [==============================] - 1s 261us/sample - loss: 0.3921 - accuracy: 0.8171 - val_loss: 0.4090 - val_accuracy: 0.8053\n",
      "Epoch 41/70\n",
      "4500/4500 [==============================] - 1s 234us/sample - loss: 0.3916 - accuracy: 0.8156 - val_loss: 0.4106 - val_accuracy: 0.8018\n",
      "Epoch 42/70\n",
      "4500/4500 [==============================] - 1s 246us/sample - loss: 0.3923 - accuracy: 0.8142 - val_loss: 0.4082 - val_accuracy: 0.8018\n",
      "Epoch 43/70\n",
      "4500/4500 [==============================] - 1s 227us/sample - loss: 0.3914 - accuracy: 0.8147 - val_loss: 0.4125 - val_accuracy: 0.7973\n",
      "Epoch 44/70\n",
      "4500/4500 [==============================] - 1s 253us/sample - loss: 0.3914 - accuracy: 0.8171 - val_loss: 0.4170 - val_accuracy: 0.8071\n",
      "Epoch 45/70\n",
      "4500/4500 [==============================] - 1s 238us/sample - loss: 0.3936 - accuracy: 0.8138 - val_loss: 0.4106 - val_accuracy: 0.8080\n",
      "Epoch 46/70\n",
      "4500/4500 [==============================] - 1s 232us/sample - loss: 0.3881 - accuracy: 0.8169 - val_loss: 0.4081 - val_accuracy: 0.8053\n",
      "Epoch 47/70\n",
      "4500/4500 [==============================] - 1s 266us/sample - loss: 0.3872 - accuracy: 0.8180 - val_loss: 0.4234 - val_accuracy: 0.7902\n",
      "Epoch 48/70\n",
      "4500/4500 [==============================] - 1s 246us/sample - loss: 0.3923 - accuracy: 0.8136 - val_loss: 0.4141 - val_accuracy: 0.7982\n",
      "Epoch 49/70\n",
      "4500/4500 [==============================] - 1s 241us/sample - loss: 0.3915 - accuracy: 0.8169 - val_loss: 0.4088 - val_accuracy: 0.8062\n",
      "Epoch 50/70\n",
      "4500/4500 [==============================] - 1s 258us/sample - loss: 0.3865 - accuracy: 0.8191 - val_loss: 0.4105 - val_accuracy: 0.8036\n",
      "Epoch 51/70\n",
      "4500/4500 [==============================] - 1s 246us/sample - loss: 0.3859 - accuracy: 0.8184 - val_loss: 0.4136 - val_accuracy: 0.7964\n",
      "Epoch 52/70\n",
      "4500/4500 [==============================] - 1s 266us/sample - loss: 0.3870 - accuracy: 0.8193 - val_loss: 0.4089 - val_accuracy: 0.8053\n",
      "Epoch 53/70\n",
      "4500/4500 [==============================] - 1s 244us/sample - loss: 0.3853 - accuracy: 0.8216 - val_loss: 0.4111 - val_accuracy: 0.8044\n",
      "Epoch 54/70\n",
      "4500/4500 [==============================] - 1s 242us/sample - loss: 0.3867 - accuracy: 0.8224 - val_loss: 0.4144 - val_accuracy: 0.8036\n",
      "Epoch 55/70\n",
      "4500/4500 [==============================] - 1s 219us/sample - loss: 0.3833 - accuracy: 0.8218 - val_loss: 0.4115 - val_accuracy: 0.7991\n",
      "Epoch 56/70\n",
      "4500/4500 [==============================] - 1s 242us/sample - loss: 0.3838 - accuracy: 0.8189 - val_loss: 0.4191 - val_accuracy: 0.8018\n",
      "Epoch 57/70\n",
      "4500/4500 [==============================] - 1s 257us/sample - loss: 0.3832 - accuracy: 0.8193 - val_loss: 0.4080 - val_accuracy: 0.8089\n",
      "Epoch 58/70\n",
      "4500/4500 [==============================] - 1s 245us/sample - loss: 0.3805 - accuracy: 0.8231 - val_loss: 0.4111 - val_accuracy: 0.8062\n",
      "Epoch 59/70\n",
      "4500/4500 [==============================] - 1s 251us/sample - loss: 0.3805 - accuracy: 0.8256 - val_loss: 0.4094 - val_accuracy: 0.8089\n",
      "Epoch 60/70\n",
      "4500/4500 [==============================] - 1s 245us/sample - loss: 0.3804 - accuracy: 0.8258 - val_loss: 0.4137 - val_accuracy: 0.8044\n",
      "Epoch 61/70\n",
      "4500/4500 [==============================] - 1s 257us/sample - loss: 0.3801 - accuracy: 0.8231 - val_loss: 0.4112 - val_accuracy: 0.7982\n",
      "Epoch 62/70\n",
      "4500/4500 [==============================] - 1s 273us/sample - loss: 0.3805 - accuracy: 0.8260 - val_loss: 0.4100 - val_accuracy: 0.8053\n",
      "Epoch 63/70\n",
      "4500/4500 [==============================] - 1s 246us/sample - loss: 0.3780 - accuracy: 0.8271 - val_loss: 0.4099 - val_accuracy: 0.8044\n",
      "Epoch 64/70\n",
      "4500/4500 [==============================] - 1s 231us/sample - loss: 0.3857 - accuracy: 0.8149 - val_loss: 0.4166 - val_accuracy: 0.7973\n",
      "Epoch 65/70\n",
      "4500/4500 [==============================] - 1s 256us/sample - loss: 0.3794 - accuracy: 0.8253 - val_loss: 0.4125 - val_accuracy: 0.8053\n",
      "Epoch 66/70\n",
      "4500/4500 [==============================] - 1s 261us/sample - loss: 0.3763 - accuracy: 0.8242 - val_loss: 0.4117 - val_accuracy: 0.7991\n",
      "Epoch 67/70\n",
      "4500/4500 [==============================] - 1s 257us/sample - loss: 0.3765 - accuracy: 0.8249 - val_loss: 0.4158 - val_accuracy: 0.8000\n",
      "Epoch 68/70\n",
      "4500/4500 [==============================] - 1s 253us/sample - loss: 0.3759 - accuracy: 0.8251 - val_loss: 0.4126 - val_accuracy: 0.8044\n",
      "Epoch 69/70\n",
      "4500/4500 [==============================] - 1s 223us/sample - loss: 0.3754 - accuracy: 0.8238 - val_loss: 0.4095 - val_accuracy: 0.8044\n",
      "Epoch 70/70\n",
      "4500/4500 [==============================] - 1s 239us/sample - loss: 0.3770 - accuracy: 0.8247 - val_loss: 0.4117 - val_accuracy: 0.8044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ac840f94c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name = \"CNN_{}\".format(int(time.time())) \n",
    "log_dir=\"E:\\\\SnehaWork\\\\AIProject\\\\TF_Logs\\\\{}\".format(Name)\n",
    "cnn = models.Sequential([\n",
    "    layers.Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(26,1)),  \n",
    "    layers.MaxPooling1D(pool_size=3),\n",
    "    \n",
    "    layers.Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=3),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(20, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#cnn.summary()\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=0)\n",
    "\n",
    "cnn.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "cnn.fit(X_train, y_train, validation_data=(X_val,y_val), batch_size=375,epochs=70, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 0s 347us/sample - loss: 0.4575 - accuracy: 0.7818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4574602220866726, 0.7818053]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test,y_test,batch_size=375)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = cnn.predict(X_test)\n",
    "#yp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting decimal into 0 and 1\n",
    "y_pred = []\n",
    "for i in yp:\n",
    "    if i>0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       999\n",
      "           1       0.65      0.52      0.58       408\n",
      "\n",
      "    accuracy                           0.78      1407\n",
      "   macro avg       0.74      0.71      0.72      1407\n",
      "weighted avg       0.77      0.78      0.77      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[886, 113],\n",
       "       [194, 214]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\n",
    "\n",
    "plt.figure(figsize = (7,4))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "tf.math.confusion_matrix(labels=y_test,predictions=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir log_dir\n",
    "#The tensorboard extension is already loaded. To reload it, use:\n",
    "#%reload_ext tensorboard\n",
    "\n",
    "#run in cmd tensorboard --logdir='E:\\SnehaWork\\AIProject\\TF_Logs\\CNN_1626995487'\n",
    "#taskkill /F /PID 15092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df1.drop('Churn',axis='columns')\n",
    "y_df = df1['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(sampling_strategy='minority')\n",
    "X_sm_train, y_sm_train = smote.fit_resample(X_train1, y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm_train = pd.DataFrame(X_sm_train, columns=X_df.columns)\n",
    "#X_train = pd.DataFrame(X_train_oversampled, columns=X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sm_train = pd.Series(y_sm_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 26, 1)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sm_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5163\n",
       "0    5163\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sm1.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_df, y_df, test_size=0.2, random_state=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm_train, X_sm_val, y_sm_train, y_sm_val = train_test_split(X_sm_train,y_sm_train,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_sm_train=X_sm_train.reshape(X_sm_train.shape[0],num_of_cols, 1).astype('float32') \n",
    "X_test1=X_test1.values.reshape(X_test1.shape[0],num_of_cols, 1).astype('float32')\n",
    "#X_sm_val=X_sm_val.values.reshape(X_sm_val.shape[0],num_of_cols, 1).astype('float32')\n",
    "\n",
    "#sometimes works as X_val.values.reshape(X_val.shape[0],26, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1407, 26, 1)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6596 samples, validate on 1650 samples\n",
      "Epoch 1/300\n",
      " 375/6596 [>.............................] - ETA: 22s - loss: 0.6939 - accuracy: 0.4720WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.150098). Check your callbacks.\n",
      "6596/6596 [==============================] - 3s 513us/sample - loss: 0.6420 - accuracy: 0.6716 - val_loss: 0.5884 - val_accuracy: 0.7309\n",
      "Epoch 2/300\n",
      "6596/6596 [==============================] - 1s 185us/sample - loss: 0.5445 - accuracy: 0.7539 - val_loss: 0.5037 - val_accuracy: 0.7521\n",
      "Epoch 3/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.4993 - accuracy: 0.7670 - val_loss: 0.4838 - val_accuracy: 0.7618\n",
      "Epoch 4/300\n",
      "6596/6596 [==============================] - 1s 194us/sample - loss: 0.4850 - accuracy: 0.7727 - val_loss: 0.4751 - val_accuracy: 0.7648\n",
      "Epoch 5/300\n",
      "6596/6596 [==============================] - 1s 200us/sample - loss: 0.4778 - accuracy: 0.7758 - val_loss: 0.4838 - val_accuracy: 0.7697\n",
      "Epoch 6/300\n",
      "6596/6596 [==============================] - 1s 224us/sample - loss: 0.4781 - accuracy: 0.7735 - val_loss: 0.4632 - val_accuracy: 0.7691\n",
      "Epoch 7/300\n",
      "6596/6596 [==============================] - 1s 214us/sample - loss: 0.4665 - accuracy: 0.7814 - val_loss: 0.4610 - val_accuracy: 0.7697\n",
      "Epoch 8/300\n",
      "6596/6596 [==============================] - 1s 211us/sample - loss: 0.4612 - accuracy: 0.7849 - val_loss: 0.4664 - val_accuracy: 0.7745\n",
      "Epoch 9/300\n",
      "6596/6596 [==============================] - 1s 216us/sample - loss: 0.4638 - accuracy: 0.7876 - val_loss: 0.4592 - val_accuracy: 0.7752\n",
      "Epoch 10/300\n",
      "6596/6596 [==============================] - 1s 216us/sample - loss: 0.4556 - accuracy: 0.7855 - val_loss: 0.4520 - val_accuracy: 0.7703\n",
      "Epoch 11/300\n",
      "6596/6596 [==============================] - 1s 227us/sample - loss: 0.4492 - accuracy: 0.7896 - val_loss: 0.4487 - val_accuracy: 0.7715\n",
      "Epoch 12/300\n",
      "6596/6596 [==============================] - 2s 249us/sample - loss: 0.4489 - accuracy: 0.7894 - val_loss: 0.4486 - val_accuracy: 0.7879\n",
      "Epoch 13/300\n",
      "6596/6596 [==============================] - 1s 208us/sample - loss: 0.4461 - accuracy: 0.7906 - val_loss: 0.4423 - val_accuracy: 0.7745\n",
      "Epoch 14/300\n",
      "6596/6596 [==============================] - 1s 219us/sample - loss: 0.4392 - accuracy: 0.7906 - val_loss: 0.4466 - val_accuracy: 0.7770\n",
      "Epoch 15/300\n",
      "6596/6596 [==============================] - 1s 205us/sample - loss: 0.4351 - accuracy: 0.7973 - val_loss: 0.4342 - val_accuracy: 0.7927\n",
      "Epoch 16/300\n",
      "6596/6596 [==============================] - 1s 209us/sample - loss: 0.4317 - accuracy: 0.8028 - val_loss: 0.4331 - val_accuracy: 0.7897\n",
      "Epoch 17/300\n",
      "6596/6596 [==============================] - 1s 219us/sample - loss: 0.4264 - accuracy: 0.8029 - val_loss: 0.4293 - val_accuracy: 0.7958\n",
      "Epoch 18/300\n",
      "6596/6596 [==============================] - 1s 200us/sample - loss: 0.4227 - accuracy: 0.8046 - val_loss: 0.4306 - val_accuracy: 0.7867\n",
      "Epoch 19/300\n",
      "6596/6596 [==============================] - 2s 256us/sample - loss: 0.4172 - accuracy: 0.8123 - val_loss: 0.4255 - val_accuracy: 0.7891\n",
      "Epoch 20/300\n",
      "6596/6596 [==============================] - 2s 260us/sample - loss: 0.4158 - accuracy: 0.8116 - val_loss: 0.4249 - val_accuracy: 0.7994\n",
      "Epoch 21/300\n",
      "6596/6596 [==============================] - 1s 226us/sample - loss: 0.4112 - accuracy: 0.8140 - val_loss: 0.4328 - val_accuracy: 0.7952\n",
      "Epoch 22/300\n",
      "6596/6596 [==============================] - 2s 235us/sample - loss: 0.4118 - accuracy: 0.8128 - val_loss: 0.4343 - val_accuracy: 0.7952\n",
      "Epoch 23/300\n",
      "6596/6596 [==============================] - 1s 215us/sample - loss: 0.4039 - accuracy: 0.8175 - val_loss: 0.4520 - val_accuracy: 0.7897\n",
      "Epoch 24/300\n",
      "6596/6596 [==============================] - 1s 193us/sample - loss: 0.4226 - accuracy: 0.8046 - val_loss: 0.4301 - val_accuracy: 0.7958\n",
      "Epoch 25/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.3985 - accuracy: 0.8202 - val_loss: 0.4137 - val_accuracy: 0.7970\n",
      "Epoch 26/300\n",
      "6596/6596 [==============================] - 1s 194us/sample - loss: 0.3912 - accuracy: 0.8241 - val_loss: 0.4133 - val_accuracy: 0.8048\n",
      "Epoch 27/300\n",
      "6596/6596 [==============================] - 2s 268us/sample - loss: 0.3904 - accuracy: 0.8240 - val_loss: 0.4035 - val_accuracy: 0.8091\n",
      "Epoch 28/300\n",
      "6596/6596 [==============================] - 1s 186us/sample - loss: 0.3839 - accuracy: 0.8310 - val_loss: 0.4024 - val_accuracy: 0.8061\n",
      "Epoch 29/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.3884 - accuracy: 0.8247 - val_loss: 0.4049 - val_accuracy: 0.8158\n",
      "Epoch 30/300\n",
      "6596/6596 [==============================] - 1s 188us/sample - loss: 0.3819 - accuracy: 0.8282 - val_loss: 0.4025 - val_accuracy: 0.8067\n",
      "Epoch 31/300\n",
      "6596/6596 [==============================] - 1s 204us/sample - loss: 0.3766 - accuracy: 0.8343 - val_loss: 0.4019 - val_accuracy: 0.8073\n",
      "Epoch 32/300\n",
      "6596/6596 [==============================] - 1s 203us/sample - loss: 0.3744 - accuracy: 0.8329 - val_loss: 0.3973 - val_accuracy: 0.8109\n",
      "Epoch 33/300\n",
      "6596/6596 [==============================] - 1s 196us/sample - loss: 0.3680 - accuracy: 0.8343 - val_loss: 0.3994 - val_accuracy: 0.8145\n",
      "Epoch 34/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.3674 - accuracy: 0.8381 - val_loss: 0.3987 - val_accuracy: 0.8170\n",
      "Epoch 35/300\n",
      "6596/6596 [==============================] - 1s 191us/sample - loss: 0.3703 - accuracy: 0.8360 - val_loss: 0.3908 - val_accuracy: 0.8188\n",
      "Epoch 36/300\n",
      "6596/6596 [==============================] - 1s 189us/sample - loss: 0.3880 - accuracy: 0.8217 - val_loss: 0.4155 - val_accuracy: 0.8048\n",
      "Epoch 37/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.3689 - accuracy: 0.8349 - val_loss: 0.3889 - val_accuracy: 0.8224\n",
      "Epoch 38/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.3566 - accuracy: 0.8434 - val_loss: 0.3899 - val_accuracy: 0.8097\n",
      "Epoch 39/300\n",
      "6596/6596 [==============================] - 1s 185us/sample - loss: 0.3539 - accuracy: 0.8417 - val_loss: 0.3960 - val_accuracy: 0.8188\n",
      "Epoch 40/300\n",
      "6596/6596 [==============================] - 1s 185us/sample - loss: 0.3569 - accuracy: 0.8408 - val_loss: 0.4053 - val_accuracy: 0.8133\n",
      "Epoch 41/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.3566 - accuracy: 0.8399 - val_loss: 0.3906 - val_accuracy: 0.8109\n",
      "Epoch 42/300\n",
      "6596/6596 [==============================] - 1s 205us/sample - loss: 0.3554 - accuracy: 0.8384 - val_loss: 0.3876 - val_accuracy: 0.8255\n",
      "Epoch 43/300\n",
      "6596/6596 [==============================] - 1s 197us/sample - loss: 0.3470 - accuracy: 0.8445 - val_loss: 0.3858 - val_accuracy: 0.8248\n",
      "Epoch 44/300\n",
      "6596/6596 [==============================] - 1s 202us/sample - loss: 0.3420 - accuracy: 0.8507 - val_loss: 0.3823 - val_accuracy: 0.8182\n",
      "Epoch 45/300\n",
      "6596/6596 [==============================] - 1s 223us/sample - loss: 0.3531 - accuracy: 0.8369 - val_loss: 0.4013 - val_accuracy: 0.8176\n",
      "Epoch 46/300\n",
      "6596/6596 [==============================] - 1s 217us/sample - loss: 0.3411 - accuracy: 0.8507 - val_loss: 0.3997 - val_accuracy: 0.8055\n",
      "Epoch 47/300\n",
      "6596/6596 [==============================] - 1s 186us/sample - loss: 0.3487 - accuracy: 0.8429 - val_loss: 0.3788 - val_accuracy: 0.8303\n",
      "Epoch 48/300\n",
      "6596/6596 [==============================] - 1s 192us/sample - loss: 0.3343 - accuracy: 0.8529 - val_loss: 0.3909 - val_accuracy: 0.8224\n",
      "Epoch 49/300\n",
      "6596/6596 [==============================] - 1s 191us/sample - loss: 0.3335 - accuracy: 0.8535 - val_loss: 0.3804 - val_accuracy: 0.8224\n",
      "Epoch 50/300\n",
      "6596/6596 [==============================] - 1s 196us/sample - loss: 0.3290 - accuracy: 0.8586 - val_loss: 0.3817 - val_accuracy: 0.8309\n",
      "Epoch 51/300\n",
      "6596/6596 [==============================] - 1s 185us/sample - loss: 0.3292 - accuracy: 0.8563 - val_loss: 0.3760 - val_accuracy: 0.8273\n",
      "Epoch 52/300\n",
      "6596/6596 [==============================] - 1s 182us/sample - loss: 0.3289 - accuracy: 0.8525 - val_loss: 0.3913 - val_accuracy: 0.8212\n",
      "Epoch 53/300\n",
      "6596/6596 [==============================] - 1s 185us/sample - loss: 0.3357 - accuracy: 0.8520 - val_loss: 0.3921 - val_accuracy: 0.8127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/300\n",
      "6596/6596 [==============================] - 1s 192us/sample - loss: 0.3258 - accuracy: 0.8563 - val_loss: 0.3741 - val_accuracy: 0.8303\n",
      "Epoch 55/300\n",
      "6596/6596 [==============================] - 1s 204us/sample - loss: 0.3250 - accuracy: 0.8532 - val_loss: 0.3762 - val_accuracy: 0.8285\n",
      "Epoch 56/300\n",
      "6596/6596 [==============================] - 1s 193us/sample - loss: 0.3296 - accuracy: 0.8529 - val_loss: 0.3769 - val_accuracy: 0.8291\n",
      "Epoch 57/300\n",
      "6596/6596 [==============================] - 1s 218us/sample - loss: 0.3285 - accuracy: 0.8552 - val_loss: 0.3840 - val_accuracy: 0.8230\n",
      "Epoch 58/300\n",
      "6596/6596 [==============================] - 1s 220us/sample - loss: 0.3216 - accuracy: 0.8525 - val_loss: 0.3896 - val_accuracy: 0.8109\n",
      "Epoch 59/300\n",
      "6596/6596 [==============================] - 1s 186us/sample - loss: 0.3259 - accuracy: 0.8551 - val_loss: 0.3801 - val_accuracy: 0.8188\n",
      "Epoch 60/300\n",
      "6596/6596 [==============================] - 2s 234us/sample - loss: 0.3353 - accuracy: 0.8508 - val_loss: 0.3994 - val_accuracy: 0.8176\n",
      "Epoch 61/300\n",
      "6596/6596 [==============================] - 1s 224us/sample - loss: 0.3191 - accuracy: 0.8579 - val_loss: 0.3662 - val_accuracy: 0.8285\n",
      "Epoch 62/300\n",
      "6596/6596 [==============================] - 1s 192us/sample - loss: 0.3179 - accuracy: 0.8560 - val_loss: 0.3741 - val_accuracy: 0.8339\n",
      "Epoch 63/300\n",
      "6596/6596 [==============================] - 1s 188us/sample - loss: 0.3122 - accuracy: 0.8636 - val_loss: 0.3732 - val_accuracy: 0.8309\n",
      "Epoch 64/300\n",
      "6596/6596 [==============================] - 1s 197us/sample - loss: 0.3093 - accuracy: 0.8626 - val_loss: 0.3696 - val_accuracy: 0.8370\n",
      "Epoch 65/300\n",
      "6596/6596 [==============================] - 1s 182us/sample - loss: 0.3077 - accuracy: 0.8619 - val_loss: 0.3768 - val_accuracy: 0.8224\n",
      "Epoch 66/300\n",
      "6596/6596 [==============================] - 1s 185us/sample - loss: 0.3178 - accuracy: 0.8549 - val_loss: 0.3757 - val_accuracy: 0.8267\n",
      "Epoch 67/300\n",
      "6596/6596 [==============================] - 1s 191us/sample - loss: 0.3065 - accuracy: 0.8610 - val_loss: 0.3688 - val_accuracy: 0.8279\n",
      "Epoch 68/300\n",
      "6596/6596 [==============================] - 1s 215us/sample - loss: 0.3062 - accuracy: 0.8661 - val_loss: 0.3657 - val_accuracy: 0.8279\n",
      "Epoch 69/300\n",
      "6596/6596 [==============================] - 1s 201us/sample - loss: 0.3058 - accuracy: 0.8683 - val_loss: 0.3775 - val_accuracy: 0.8358\n",
      "Epoch 70/300\n",
      "6596/6596 [==============================] - 1s 208us/sample - loss: 0.3094 - accuracy: 0.8596 - val_loss: 0.3677 - val_accuracy: 0.8327\n",
      "Epoch 71/300\n",
      "6596/6596 [==============================] - 1s 190us/sample - loss: 0.3037 - accuracy: 0.8667 - val_loss: 0.4003 - val_accuracy: 0.8194\n",
      "Epoch 72/300\n",
      "6596/6596 [==============================] - 1s 218us/sample - loss: 0.3176 - accuracy: 0.8566 - val_loss: 0.3927 - val_accuracy: 0.8188\n",
      "Epoch 73/300\n",
      "6596/6596 [==============================] - 1s 218us/sample - loss: 0.3074 - accuracy: 0.8614 - val_loss: 0.3803 - val_accuracy: 0.8297\n",
      "Epoch 74/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.3085 - accuracy: 0.8623 - val_loss: 0.3684 - val_accuracy: 0.8255\n",
      "Epoch 75/300\n",
      "6596/6596 [==============================] - 1s 193us/sample - loss: 0.3039 - accuracy: 0.8670 - val_loss: 0.3678 - val_accuracy: 0.8345\n",
      "Epoch 76/300\n",
      "6596/6596 [==============================] - 1s 178us/sample - loss: 0.3060 - accuracy: 0.8601 - val_loss: 0.3872 - val_accuracy: 0.8182\n",
      "Epoch 77/300\n",
      "6596/6596 [==============================] - 1s 189us/sample - loss: 0.3060 - accuracy: 0.8631 - val_loss: 0.3666 - val_accuracy: 0.8273\n",
      "Epoch 78/300\n",
      "6596/6596 [==============================] - 1s 205us/sample - loss: 0.3110 - accuracy: 0.8607 - val_loss: 0.3713 - val_accuracy: 0.8388\n",
      "Epoch 79/300\n",
      "6596/6596 [==============================] - 1s 220us/sample - loss: 0.3020 - accuracy: 0.8676 - val_loss: 0.3732 - val_accuracy: 0.8273\n",
      "Epoch 80/300\n",
      "6596/6596 [==============================] - 1s 185us/sample - loss: 0.3124 - accuracy: 0.8573 - val_loss: 0.3721 - val_accuracy: 0.8339\n",
      "Epoch 81/300\n",
      "6596/6596 [==============================] - 1s 190us/sample - loss: 0.2983 - accuracy: 0.8673 - val_loss: 0.3646 - val_accuracy: 0.8297\n",
      "Epoch 82/300\n",
      "6596/6596 [==============================] - 1s 206us/sample - loss: 0.2931 - accuracy: 0.8705 - val_loss: 0.3667 - val_accuracy: 0.8345\n",
      "Epoch 83/300\n",
      "6596/6596 [==============================] - 1s 210us/sample - loss: 0.2900 - accuracy: 0.8743 - val_loss: 0.3666 - val_accuracy: 0.8261\n",
      "Epoch 84/300\n",
      "6596/6596 [==============================] - 2s 257us/sample - loss: 0.2915 - accuracy: 0.8710 - val_loss: 0.3760 - val_accuracy: 0.8255\n",
      "Epoch 85/300\n",
      "6596/6596 [==============================] - 2s 240us/sample - loss: 0.2929 - accuracy: 0.8648 - val_loss: 0.3765 - val_accuracy: 0.8339\n",
      "Epoch 86/300\n",
      "6596/6596 [==============================] - 1s 200us/sample - loss: 0.3188 - accuracy: 0.8543 - val_loss: 0.3936 - val_accuracy: 0.8200\n",
      "Epoch 87/300\n",
      "6596/6596 [==============================] - 2s 245us/sample - loss: 0.3005 - accuracy: 0.8652 - val_loss: 0.3772 - val_accuracy: 0.8267\n",
      "Epoch 88/300\n",
      "6596/6596 [==============================] - 1s 219us/sample - loss: 0.2962 - accuracy: 0.8645 - val_loss: 0.3949 - val_accuracy: 0.8267\n",
      "Epoch 89/300\n",
      "6596/6596 [==============================] - 1s 192us/sample - loss: 0.2916 - accuracy: 0.8687 - val_loss: 0.3761 - val_accuracy: 0.8285\n",
      "Epoch 90/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.2931 - accuracy: 0.8737 - val_loss: 0.3759 - val_accuracy: 0.8364\n",
      "Epoch 91/300\n",
      "6596/6596 [==============================] - 1s 198us/sample - loss: 0.2834 - accuracy: 0.8758 - val_loss: 0.3771 - val_accuracy: 0.8273\n",
      "Epoch 92/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2837 - accuracy: 0.8778 - val_loss: 0.3784 - val_accuracy: 0.8279\n",
      "Epoch 93/300\n",
      "6596/6596 [==============================] - 1s 207us/sample - loss: 0.2917 - accuracy: 0.8692 - val_loss: 0.3673 - val_accuracy: 0.8291\n",
      "Epoch 94/300\n",
      "6596/6596 [==============================] - 2s 236us/sample - loss: 0.2904 - accuracy: 0.8739 - val_loss: 0.3681 - val_accuracy: 0.8291\n",
      "Epoch 95/300\n",
      "6596/6596 [==============================] - 2s 253us/sample - loss: 0.2854 - accuracy: 0.8722 - val_loss: 0.3767 - val_accuracy: 0.8212\n",
      "Epoch 96/300\n",
      "6596/6596 [==============================] - 1s 189us/sample - loss: 0.2910 - accuracy: 0.8742 - val_loss: 0.3695 - val_accuracy: 0.8382\n",
      "Epoch 97/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.2779 - accuracy: 0.8796 - val_loss: 0.3647 - val_accuracy: 0.8394\n",
      "Epoch 98/300\n",
      "6596/6596 [==============================] - 1s 205us/sample - loss: 0.2807 - accuracy: 0.8767 - val_loss: 0.3741 - val_accuracy: 0.8261\n",
      "Epoch 99/300\n",
      "6596/6596 [==============================] - 1s 192us/sample - loss: 0.2929 - accuracy: 0.8684 - val_loss: 0.3753 - val_accuracy: 0.8309\n",
      "Epoch 100/300\n",
      "6596/6596 [==============================] - 2s 253us/sample - loss: 0.2788 - accuracy: 0.8783 - val_loss: 0.3990 - val_accuracy: 0.8164\n",
      "Epoch 101/300\n",
      "6596/6596 [==============================] - 1s 189us/sample - loss: 0.2798 - accuracy: 0.8778 - val_loss: 0.3619 - val_accuracy: 0.8279\n",
      "Epoch 102/300\n",
      "6596/6596 [==============================] - 1s 168us/sample - loss: 0.2788 - accuracy: 0.8758 - val_loss: 0.3730 - val_accuracy: 0.8309\n",
      "Epoch 103/300\n",
      "6596/6596 [==============================] - 1s 179us/sample - loss: 0.2750 - accuracy: 0.8761 - val_loss: 0.3611 - val_accuracy: 0.8376\n",
      "Epoch 104/300\n",
      "6596/6596 [==============================] - 1s 186us/sample - loss: 0.2766 - accuracy: 0.8799 - val_loss: 0.3774 - val_accuracy: 0.8242\n",
      "Epoch 105/300\n",
      "6596/6596 [==============================] - 1s 222us/sample - loss: 0.2781 - accuracy: 0.8754 - val_loss: 0.3661 - val_accuracy: 0.8370\n",
      "Epoch 106/300\n",
      "6596/6596 [==============================] - 1s 209us/sample - loss: 0.2709 - accuracy: 0.8819 - val_loss: 0.3713 - val_accuracy: 0.8236\n",
      "Epoch 107/300\n",
      "6596/6596 [==============================] - 1s 199us/sample - loss: 0.2709 - accuracy: 0.8828 - val_loss: 0.3621 - val_accuracy: 0.8406\n",
      "Epoch 108/300\n",
      "6596/6596 [==============================] - 1s 199us/sample - loss: 0.2722 - accuracy: 0.8773 - val_loss: 0.3719 - val_accuracy: 0.8297.2687 - ac\n",
      "Epoch 109/300\n",
      "6596/6596 [==============================] - 1s 204us/sample - loss: 0.2730 - accuracy: 0.8798 - val_loss: 0.3748 - val_accuracy: 0.8261\n",
      "Epoch 110/300\n",
      "6596/6596 [==============================] - 1s 214us/sample - loss: 0.2764 - accuracy: 0.8770 - val_loss: 0.3761 - val_accuracy: 0.8261\n",
      "Epoch 111/300\n",
      "6596/6596 [==============================] - 2s 243us/sample - loss: 0.2730 - accuracy: 0.8798 - val_loss: 0.3734 - val_accuracy: 0.8261\n",
      "Epoch 112/300\n",
      "6596/6596 [==============================] - 1s 213us/sample - loss: 0.2735 - accuracy: 0.8804 - val_loss: 0.3777 - val_accuracy: 0.8382\n",
      "Epoch 113/300\n",
      "6596/6596 [==============================] - 2s 249us/sample - loss: 0.2842 - accuracy: 0.8686 - val_loss: 0.4484 - val_accuracy: 0.8042\n",
      "Epoch 114/300\n",
      "6596/6596 [==============================] - 1s 201us/sample - loss: 0.2847 - accuracy: 0.8711 - val_loss: 0.3703 - val_accuracy: 0.8364\n",
      "Epoch 115/300\n",
      "6596/6596 [==============================] - 1s 197us/sample - loss: 0.2851 - accuracy: 0.8730 - val_loss: 0.3763 - val_accuracy: 0.8345\n",
      "Epoch 116/300\n",
      "6596/6596 [==============================] - 1s 213us/sample - loss: 0.2790 - accuracy: 0.8748 - val_loss: 0.4187 - val_accuracy: 0.8097\n",
      "Epoch 117/300\n",
      "6596/6596 [==============================] - 1s 210us/sample - loss: 0.2755 - accuracy: 0.8787 - val_loss: 0.3770 - val_accuracy: 0.8394\n",
      "Epoch 118/300\n",
      "6596/6596 [==============================] - 1s 215us/sample - loss: 0.2716 - accuracy: 0.8804 - val_loss: 0.3642 - val_accuracy: 0.8412\n",
      "Epoch 119/300\n",
      "6596/6596 [==============================] - 1s 205us/sample - loss: 0.2639 - accuracy: 0.8846 - val_loss: 0.3758 - val_accuracy: 0.8339\n",
      "Epoch 120/300\n",
      "6596/6596 [==============================] - 1s 202us/sample - loss: 0.2670 - accuracy: 0.8860 - val_loss: 0.3712 - val_accuracy: 0.8279\n",
      "Epoch 121/300\n",
      "6596/6596 [==============================] - 1s 206us/sample - loss: 0.2642 - accuracy: 0.8843 - val_loss: 0.4012 - val_accuracy: 0.8267\n",
      "Epoch 122/300\n",
      "6596/6596 [==============================] - 1s 185us/sample - loss: 0.2781 - accuracy: 0.8778 - val_loss: 0.3719 - val_accuracy: 0.8321\n",
      "Epoch 123/300\n",
      "6596/6596 [==============================] - 1s 188us/sample - loss: 0.2692 - accuracy: 0.8795 - val_loss: 0.3759 - val_accuracy: 0.8255\n",
      "Epoch 124/300\n",
      "6596/6596 [==============================] - 1s 182us/sample - loss: 0.2614 - accuracy: 0.8863 - val_loss: 0.3729 - val_accuracy: 0.8285\n",
      "Epoch 125/300\n",
      "6596/6596 [==============================] - 1s 197us/sample - loss: 0.2654 - accuracy: 0.8857 - val_loss: 0.3985 - val_accuracy: 0.8158\n",
      "Epoch 126/300\n",
      "6596/6596 [==============================] - 1s 202us/sample - loss: 0.2661 - accuracy: 0.8813 - val_loss: 0.3794 - val_accuracy: 0.8297\n",
      "Epoch 127/300\n",
      "6596/6596 [==============================] - 1s 200us/sample - loss: 0.2698 - accuracy: 0.8805 - val_loss: 0.3724 - val_accuracy: 0.8333\n",
      "Epoch 128/300\n",
      "6596/6596 [==============================] - 1s 195us/sample - loss: 0.2563 - accuracy: 0.8857 - val_loss: 0.3839 - val_accuracy: 0.8261\n",
      "Epoch 129/300\n",
      "6596/6596 [==============================] - 1s 202us/sample - loss: 0.2617 - accuracy: 0.8824 - val_loss: 0.3841 - val_accuracy: 0.8291\n",
      "Epoch 130/300\n",
      "6596/6596 [==============================] - 1s 193us/sample - loss: 0.2657 - accuracy: 0.8817 - val_loss: 0.3706 - val_accuracy: 0.8364\n",
      "Epoch 131/300\n",
      "6596/6596 [==============================] - 1s 191us/sample - loss: 0.2556 - accuracy: 0.8871 - val_loss: 0.4135 - val_accuracy: 0.8097\n",
      "Epoch 132/300\n",
      "6596/6596 [==============================] - 1s 196us/sample - loss: 0.2718 - accuracy: 0.8780 - val_loss: 0.3764 - val_accuracy: 0.8303\n",
      "Epoch 133/300\n",
      "6596/6596 [==============================] - 1s 191us/sample - loss: 0.2522 - accuracy: 0.8910 - val_loss: 0.3759 - val_accuracy: 0.8333\n",
      "Epoch 134/300\n",
      "6596/6596 [==============================] - 1s 182us/sample - loss: 0.2573 - accuracy: 0.8913 - val_loss: 0.3868 - val_accuracy: 0.8188\n",
      "Epoch 135/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2607 - accuracy: 0.8871 - val_loss: 0.3784 - val_accuracy: 0.8273\n",
      "Epoch 136/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2551 - accuracy: 0.8904 - val_loss: 0.3920 - val_accuracy: 0.8242\n",
      "Epoch 137/300\n",
      "6596/6596 [==============================] - 1s 182us/sample - loss: 0.2605 - accuracy: 0.8843 - val_loss: 0.3750 - val_accuracy: 0.8273\n",
      "Epoch 138/300\n",
      "6596/6596 [==============================] - 1s 190us/sample - loss: 0.2684 - accuracy: 0.8813 - val_loss: 0.4364 - val_accuracy: 0.8109\n",
      "Epoch 139/300\n",
      "6596/6596 [==============================] - 1s 204us/sample - loss: 0.2636 - accuracy: 0.8867 - val_loss: 0.3751 - val_accuracy: 0.8358\n",
      "Epoch 140/300\n",
      "6596/6596 [==============================] - 1s 181us/sample - loss: 0.2540 - accuracy: 0.8887 - val_loss: 0.3877 - val_accuracy: 0.8273\n",
      "Epoch 141/300\n",
      "6596/6596 [==============================] - 1s 209us/sample - loss: 0.2525 - accuracy: 0.8883 - val_loss: 0.3715 - val_accuracy: 0.8327\n",
      "Epoch 142/300\n",
      "6596/6596 [==============================] - 1s 200us/sample - loss: 0.2540 - accuracy: 0.8893 - val_loss: 0.3816 - val_accuracy: 0.8418\n",
      "Epoch 143/300\n",
      "6596/6596 [==============================] - 1s 210us/sample - loss: 0.2483 - accuracy: 0.8965 - val_loss: 0.3925 - val_accuracy: 0.8273\n",
      "Epoch 144/300\n",
      "6596/6596 [==============================] - 1s 180us/sample - loss: 0.2599 - accuracy: 0.8817 - val_loss: 0.3978 - val_accuracy: 0.8218\n",
      "Epoch 145/300\n",
      "6596/6596 [==============================] - 1s 185us/sample - loss: 0.2779 - accuracy: 0.8742 - val_loss: 0.4518 - val_accuracy: 0.8145\n",
      "Epoch 146/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.2656 - accuracy: 0.8840 - val_loss: 0.4155 - val_accuracy: 0.8218\n",
      "Epoch 147/300\n",
      "6596/6596 [==============================] - 1s 197us/sample - loss: 0.2598 - accuracy: 0.8822 - val_loss: 0.3794 - val_accuracy: 0.8400\n",
      "Epoch 148/300\n",
      "6596/6596 [==============================] - 1s 168us/sample - loss: 0.2474 - accuracy: 0.8937 - val_loss: 0.3710 - val_accuracy: 0.8424\n",
      "Epoch 149/300\n",
      "6596/6596 [==============================] - 1s 175us/sample - loss: 0.2458 - accuracy: 0.8948 - val_loss: 0.3905 - val_accuracy: 0.8139\n",
      "Epoch 150/300\n",
      "6596/6596 [==============================] - 1s 176us/sample - loss: 0.2543 - accuracy: 0.8871 - val_loss: 0.3876 - val_accuracy: 0.8376\n",
      "Epoch 151/300\n",
      "6596/6596 [==============================] - 1s 172us/sample - loss: 0.2437 - accuracy: 0.8957 - val_loss: 0.3795 - val_accuracy: 0.8370\n",
      "Epoch 152/300\n",
      "6596/6596 [==============================] - 1s 165us/sample - loss: 0.2494 - accuracy: 0.8910 - val_loss: 0.3931 - val_accuracy: 0.8376\n",
      "Epoch 153/300\n",
      "6596/6596 [==============================] - 1s 178us/sample - loss: 0.2493 - accuracy: 0.8939 - val_loss: 0.4131 - val_accuracy: 0.8109\n",
      "Epoch 154/300\n",
      "6596/6596 [==============================] - 1s 200us/sample - loss: 0.2603 - accuracy: 0.8807 - val_loss: 0.3847 - val_accuracy: 0.8339\n",
      "Epoch 155/300\n",
      "6596/6596 [==============================] - 1s 209us/sample - loss: 0.2411 - accuracy: 0.8946 - val_loss: 0.3791 - val_accuracy: 0.8327\n",
      "Epoch 156/300\n",
      "6596/6596 [==============================] - 1s 172us/sample - loss: 0.2459 - accuracy: 0.8961 - val_loss: 0.4405 - val_accuracy: 0.8079\n",
      "Epoch 157/300\n",
      "6596/6596 [==============================] - 1s 178us/sample - loss: 0.2572 - accuracy: 0.8874 - val_loss: 0.3872 - val_accuracy: 0.8303\n",
      "Epoch 158/300\n",
      "6596/6596 [==============================] - 1s 176us/sample - loss: 0.2557 - accuracy: 0.8874 - val_loss: 0.3798 - val_accuracy: 0.8352\n",
      "Epoch 159/300\n",
      "6596/6596 [==============================] - 1s 168us/sample - loss: 0.2410 - accuracy: 0.8966 - val_loss: 0.3778 - val_accuracy: 0.8242\n",
      "Epoch 160/300\n",
      "6596/6596 [==============================] - 1s 175us/sample - loss: 0.2382 - accuracy: 0.8990 - val_loss: 0.3835 - val_accuracy: 0.8327\n",
      "Epoch 161/300\n",
      "6596/6596 [==============================] - 1s 175us/sample - loss: 0.2453 - accuracy: 0.8918 - val_loss: 0.3797 - val_accuracy: 0.8248\n",
      "Epoch 162/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6596/6596 [==============================] - 1s 175us/sample - loss: 0.2493 - accuracy: 0.8881 - val_loss: 0.3838 - val_accuracy: 0.8364\n",
      "Epoch 163/300\n",
      "6596/6596 [==============================] - 2s 236us/sample - loss: 0.2389 - accuracy: 0.9002 - val_loss: 0.3813 - val_accuracy: 0.8327\n",
      "Epoch 164/300\n",
      "6596/6596 [==============================] - 1s 225us/sample - loss: 0.2373 - accuracy: 0.8984 - val_loss: 0.4008 - val_accuracy: 0.8200\n",
      "Epoch 165/300\n",
      "6596/6596 [==============================] - 1s 167us/sample - loss: 0.2442 - accuracy: 0.8934 - val_loss: 0.3768 - val_accuracy: 0.8400\n",
      "Epoch 166/300\n",
      "6596/6596 [==============================] - 1s 173us/sample - loss: 0.2478 - accuracy: 0.8911 - val_loss: 0.4440 - val_accuracy: 0.8145\n",
      "Epoch 167/300\n",
      "6596/6596 [==============================] - 1s 182us/sample - loss: 0.2520 - accuracy: 0.8864 - val_loss: 0.4040 - val_accuracy: 0.8297\n",
      "Epoch 168/300\n",
      "6596/6596 [==============================] - 1s 191us/sample - loss: 0.2526 - accuracy: 0.8858 - val_loss: 0.4143 - val_accuracy: 0.8236\n",
      "Epoch 169/300\n",
      "6596/6596 [==============================] - 1s 177us/sample - loss: 0.2402 - accuracy: 0.8955 - val_loss: 0.3893 - val_accuracy: 0.8315\n",
      "Epoch 170/300\n",
      "6596/6596 [==============================] - 1s 170us/sample - loss: 0.2363 - accuracy: 0.8955 - val_loss: 0.3874 - val_accuracy: 0.8212\n",
      "Epoch 171/300\n",
      "6596/6596 [==============================] - 1s 190us/sample - loss: 0.2448 - accuracy: 0.8901 - val_loss: 0.3935 - val_accuracy: 0.8321\n",
      "Epoch 172/300\n",
      "6596/6596 [==============================] - 1s 171us/sample - loss: 0.2353 - accuracy: 0.9008 - val_loss: 0.3863 - val_accuracy: 0.8388\n",
      "Epoch 173/300\n",
      "6596/6596 [==============================] - 1s 178us/sample - loss: 0.2288 - accuracy: 0.9013 - val_loss: 0.3866 - val_accuracy: 0.8382\n",
      "Epoch 174/300\n",
      "6596/6596 [==============================] - 1s 207us/sample - loss: 0.2371 - accuracy: 0.8955 - val_loss: 0.4011 - val_accuracy: 0.8285\n",
      "Epoch 175/300\n",
      "6596/6596 [==============================] - 1s 209us/sample - loss: 0.2330 - accuracy: 0.9002 - val_loss: 0.3901 - val_accuracy: 0.8315\n",
      "Epoch 176/300\n",
      "6596/6596 [==============================] - 1s 188us/sample - loss: 0.2381 - accuracy: 0.8969 - val_loss: 0.3857 - val_accuracy: 0.8261\n",
      "Epoch 177/300\n",
      "6596/6596 [==============================] - 1s 171us/sample - loss: 0.2337 - accuracy: 0.8995 - val_loss: 0.4196 - val_accuracy: 0.8164\n",
      "Epoch 178/300\n",
      "6596/6596 [==============================] - 1s 168us/sample - loss: 0.2379 - accuracy: 0.8966 - val_loss: 0.4029 - val_accuracy: 0.8212\n",
      "Epoch 179/300\n",
      "6596/6596 [==============================] - 1s 170us/sample - loss: 0.2407 - accuracy: 0.8930 - val_loss: 0.3913 - val_accuracy: 0.8358\n",
      "Epoch 180/300\n",
      "6596/6596 [==============================] - 1s 178us/sample - loss: 0.2374 - accuracy: 0.8943 - val_loss: 0.3962 - val_accuracy: 0.8261\n",
      "Epoch 181/300\n",
      "6596/6596 [==============================] - 1s 193us/sample - loss: 0.2310 - accuracy: 0.9015 - val_loss: 0.4010 - val_accuracy: 0.8273\n",
      "Epoch 182/300\n",
      "6596/6596 [==============================] - 1s 178us/sample - loss: 0.2287 - accuracy: 0.9010 - val_loss: 0.3924 - val_accuracy: 0.8418\n",
      "Epoch 183/300\n",
      "6596/6596 [==============================] - 1s 192us/sample - loss: 0.2374 - accuracy: 0.8946 - val_loss: 0.4016 - val_accuracy: 0.8303\n",
      "Epoch 184/300\n",
      "6596/6596 [==============================] - 1s 193us/sample - loss: 0.2399 - accuracy: 0.8952 - val_loss: 0.4663 - val_accuracy: 0.7994\n",
      "Epoch 185/300\n",
      "6596/6596 [==============================] - 1s 175us/sample - loss: 0.2483 - accuracy: 0.8872 - val_loss: 0.3985 - val_accuracy: 0.8315\n",
      "Epoch 186/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2380 - accuracy: 0.8928 - val_loss: 0.4213 - val_accuracy: 0.8145\n",
      "Epoch 187/300\n",
      "6596/6596 [==============================] - 1s 177us/sample - loss: 0.2394 - accuracy: 0.8969 - val_loss: 0.4026 - val_accuracy: 0.8285\n",
      "Epoch 188/300\n",
      "6596/6596 [==============================] - 1s 190us/sample - loss: 0.2276 - accuracy: 0.9022 - val_loss: 0.4186 - val_accuracy: 0.8206\n",
      "Epoch 189/300\n",
      "6596/6596 [==============================] - 1s 190us/sample - loss: 0.2331 - accuracy: 0.8954 - val_loss: 0.4291 - val_accuracy: 0.8224\n",
      "Epoch 190/300\n",
      "6596/6596 [==============================] - 1s 190us/sample - loss: 0.2491 - accuracy: 0.8895 - val_loss: 0.3931 - val_accuracy: 0.8291\n",
      "Epoch 191/300\n",
      "6596/6596 [==============================] - 1s 217us/sample - loss: 0.2286 - accuracy: 0.9022 - val_loss: 0.4023 - val_accuracy: 0.8303\n",
      "Epoch 192/300\n",
      "6596/6596 [==============================] - 1s 223us/sample - loss: 0.2342 - accuracy: 0.9001 - val_loss: 0.4170 - val_accuracy: 0.8242\n",
      "Epoch 193/300\n",
      "6596/6596 [==============================] - 3s 435us/sample - loss: 0.2346 - accuracy: 0.8981 - val_loss: 0.4194 - val_accuracy: 0.8230\n",
      "Epoch 194/300\n",
      "6596/6596 [==============================] - 2s 257us/sample - loss: 0.2239 - accuracy: 0.9043 - val_loss: 0.3915 - val_accuracy: 0.8388\n",
      "Epoch 195/300\n",
      "6596/6596 [==============================] - 1s 219us/sample - loss: 0.2274 - accuracy: 0.9025 - val_loss: 0.4231 - val_accuracy: 0.8242\n",
      "Epoch 196/300\n",
      "6596/6596 [==============================] - 1s 211us/sample - loss: 0.2409 - accuracy: 0.8948 - val_loss: 0.4393 - val_accuracy: 0.8194\n",
      "Epoch 197/300\n",
      "6596/6596 [==============================] - 1s 196us/sample - loss: 0.2376 - accuracy: 0.8958 - val_loss: 0.3946 - val_accuracy: 0.8339\n",
      "Epoch 198/300\n",
      "6596/6596 [==============================] - 1s 192us/sample - loss: 0.2278 - accuracy: 0.8996 - val_loss: 0.4159 - val_accuracy: 0.8206\n",
      "Epoch 199/300\n",
      "6596/6596 [==============================] - 1s 185us/sample - loss: 0.2304 - accuracy: 0.8965 - val_loss: 0.4229 - val_accuracy: 0.8273\n",
      "Epoch 200/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.2348 - accuracy: 0.8946 - val_loss: 0.4069 - val_accuracy: 0.8273\n",
      "Epoch 201/300\n",
      "6596/6596 [==============================] - 1s 190us/sample - loss: 0.2294 - accuracy: 0.8978 - val_loss: 0.4016 - val_accuracy: 0.8242\n",
      "Epoch 202/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2241 - accuracy: 0.9010 - val_loss: 0.4057 - val_accuracy: 0.8388\n",
      "Epoch 203/300\n",
      "6596/6596 [==============================] - 1s 185us/sample - loss: 0.2208 - accuracy: 0.9049 - val_loss: 0.3991 - val_accuracy: 0.8291\n",
      "Epoch 204/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.2225 - accuracy: 0.9037 - val_loss: 0.4027 - val_accuracy: 0.8291\n",
      "Epoch 205/300\n",
      "6596/6596 [==============================] - 1s 188us/sample - loss: 0.2149 - accuracy: 0.9086 - val_loss: 0.3965 - val_accuracy: 0.8388\n",
      "Epoch 206/300\n",
      "6596/6596 [==============================] - 1s 190us/sample - loss: 0.2263 - accuracy: 0.8981 - val_loss: 0.4107 - val_accuracy: 0.8352\n",
      "Epoch 207/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2196 - accuracy: 0.9018 - val_loss: 0.4106 - val_accuracy: 0.8321\n",
      "Epoch 208/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2378 - accuracy: 0.8943 - val_loss: 0.4225 - val_accuracy: 0.8291\n",
      "Epoch 209/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2186 - accuracy: 0.9045 - val_loss: 0.4112 - val_accuracy: 0.8291\n",
      "Epoch 210/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2248 - accuracy: 0.9028 - val_loss: 0.4090 - val_accuracy: 0.8388\n",
      "Epoch 211/300\n",
      "6596/6596 [==============================] - 1s 189us/sample - loss: 0.2393 - accuracy: 0.8937 - val_loss: 0.4541 - val_accuracy: 0.8139\n",
      "Epoch 212/300\n",
      "6596/6596 [==============================] - 1s 193us/sample - loss: 0.2198 - accuracy: 0.9039 - val_loss: 0.4221 - val_accuracy: 0.8248\n",
      "Epoch 213/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2261 - accuracy: 0.9019 - val_loss: 0.4123 - val_accuracy: 0.8224\n",
      "Epoch 214/300\n",
      "6596/6596 [==============================] - 1s 200us/sample - loss: 0.2369 - accuracy: 0.8930 - val_loss: 0.4217 - val_accuracy: 0.8255\n",
      "Epoch 215/300\n",
      "6596/6596 [==============================] - 1s 197us/sample - loss: 0.2187 - accuracy: 0.9049 - val_loss: 0.4357 - val_accuracy: 0.8242\n",
      "Epoch 216/300\n",
      "6596/6596 [==============================] - 1s 200us/sample - loss: 0.2240 - accuracy: 0.9033 - val_loss: 0.4071 - val_accuracy: 0.8345\n",
      "Epoch 217/300\n",
      "6596/6596 [==============================] - 1s 201us/sample - loss: 0.2140 - accuracy: 0.9077 - val_loss: 0.4104 - val_accuracy: 0.8321\n",
      "Epoch 218/300\n",
      "6596/6596 [==============================] - 1s 190us/sample - loss: 0.2216 - accuracy: 0.9039 - val_loss: 0.4750 - val_accuracy: 0.8170\n",
      "Epoch 219/300\n",
      "6596/6596 [==============================] - 1s 192us/sample - loss: 0.2381 - accuracy: 0.8942 - val_loss: 0.4103 - val_accuracy: 0.8285\n",
      "Epoch 220/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.2204 - accuracy: 0.9049 - val_loss: 0.4071 - val_accuracy: 0.8352\n",
      "Epoch 221/300\n",
      "6596/6596 [==============================] - 1s 188us/sample - loss: 0.2178 - accuracy: 0.9068 - val_loss: 0.4262 - val_accuracy: 0.8291\n",
      "Epoch 222/300\n",
      "6596/6596 [==============================] - 1s 190us/sample - loss: 0.2169 - accuracy: 0.9046 - val_loss: 0.4143 - val_accuracy: 0.8248\n",
      "Epoch 223/300\n",
      "6596/6596 [==============================] - 1s 182us/sample - loss: 0.2183 - accuracy: 0.9039 - val_loss: 0.4170 - val_accuracy: 0.8279\n",
      "Epoch 224/300\n",
      "6596/6596 [==============================] - 1s 185us/sample - loss: 0.2206 - accuracy: 0.9028 - val_loss: 0.4136 - val_accuracy: 0.8273\n",
      "Epoch 225/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2202 - accuracy: 0.9060 - val_loss: 0.4168 - val_accuracy: 0.8291\n",
      "Epoch 226/300\n",
      "6596/6596 [==============================] - 1s 188us/sample - loss: 0.2155 - accuracy: 0.9052 - val_loss: 0.4171 - val_accuracy: 0.8303\n",
      "Epoch 227/300\n",
      "6596/6596 [==============================] - 1s 185us/sample - loss: 0.2117 - accuracy: 0.9084 - val_loss: 0.4064 - val_accuracy: 0.8430\n",
      "Epoch 228/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2103 - accuracy: 0.9109 - val_loss: 0.4460 - val_accuracy: 0.8164\n",
      "Epoch 229/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.2137 - accuracy: 0.9071 - val_loss: 0.4129 - val_accuracy: 0.8352\n",
      "Epoch 230/300\n",
      "6596/6596 [==============================] - 1s 195us/sample - loss: 0.2152 - accuracy: 0.9068 - val_loss: 0.4121 - val_accuracy: 0.8309\n",
      "Epoch 231/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.2115 - accuracy: 0.9081 - val_loss: 0.4795 - val_accuracy: 0.8127\n",
      "Epoch 232/300\n",
      "6596/6596 [==============================] - 1s 195us/sample - loss: 0.2224 - accuracy: 0.8998 - val_loss: 0.4074 - val_accuracy: 0.8394\n",
      "Epoch 233/300\n",
      "6596/6596 [==============================] - 1s 192us/sample - loss: 0.2126 - accuracy: 0.9062 - val_loss: 0.4179 - val_accuracy: 0.8236\n",
      "Epoch 234/300\n",
      "6596/6596 [==============================] - 1s 200us/sample - loss: 0.2081 - accuracy: 0.9090 - val_loss: 0.4362 - val_accuracy: 0.8182\n",
      "Epoch 235/300\n",
      "6596/6596 [==============================] - 1s 176us/sample - loss: 0.2144 - accuracy: 0.9046 - val_loss: 0.4232 - val_accuracy: 0.8255\n",
      "Epoch 236/300\n",
      "6596/6596 [==============================] - 1s 176us/sample - loss: 0.2062 - accuracy: 0.9122 - val_loss: 0.4374 - val_accuracy: 0.8291\n",
      "Epoch 237/300\n",
      "6596/6596 [==============================] - 1s 185us/sample - loss: 0.2178 - accuracy: 0.9040 - val_loss: 0.4111 - val_accuracy: 0.8285\n",
      "Epoch 238/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2161 - accuracy: 0.9086 - val_loss: 0.4725 - val_accuracy: 0.8212\n",
      "Epoch 239/300\n",
      "6596/6596 [==============================] - 1s 173us/sample - loss: 0.2126 - accuracy: 0.9087 - val_loss: 0.4112 - val_accuracy: 0.8394\n",
      "Epoch 240/300\n",
      "6596/6596 [==============================] - 1s 180us/sample - loss: 0.2079 - accuracy: 0.9122 - val_loss: 0.4449 - val_accuracy: 0.8176\n",
      "Epoch 241/300\n",
      "6596/6596 [==============================] - 1s 175us/sample - loss: 0.2136 - accuracy: 0.9075 - val_loss: 0.4280 - val_accuracy: 0.8285\n",
      "Epoch 242/300\n",
      "6596/6596 [==============================] - 1s 187us/sample - loss: 0.2184 - accuracy: 0.9060 - val_loss: 0.4139 - val_accuracy: 0.8309\n",
      "Epoch 243/300\n",
      "6596/6596 [==============================] - 1s 197us/sample - loss: 0.2088 - accuracy: 0.9106 - val_loss: 0.4257 - val_accuracy: 0.8285\n",
      "Epoch 244/300\n",
      "6596/6596 [==============================] - 1s 197us/sample - loss: 0.2088 - accuracy: 0.9113 - val_loss: 0.4359 - val_accuracy: 0.8230\n",
      "Epoch 245/300\n",
      "6596/6596 [==============================] - 1s 190us/sample - loss: 0.2707 - accuracy: 0.8795 - val_loss: 0.4520 - val_accuracy: 0.8309\n",
      "Epoch 246/300\n",
      "6596/6596 [==============================] - 1s 220us/sample - loss: 0.2424 - accuracy: 0.8905 - val_loss: 0.4684 - val_accuracy: 0.8182\n",
      "Epoch 247/300\n",
      "6596/6596 [==============================] - 1s 192us/sample - loss: 0.2322 - accuracy: 0.8977 - val_loss: 0.4440 - val_accuracy: 0.8327\n",
      "Epoch 248/300\n",
      "6596/6596 [==============================] - 1s 186us/sample - loss: 0.2103 - accuracy: 0.9078 - val_loss: 0.4176 - val_accuracy: 0.8345\n",
      "Epoch 249/300\n",
      "6596/6596 [==============================] - 1s 188us/sample - loss: 0.2020 - accuracy: 0.9140 - val_loss: 0.4256 - val_accuracy: 0.8273\n",
      "Epoch 250/300\n",
      "6596/6596 [==============================] - 1s 174us/sample - loss: 0.2071 - accuracy: 0.9110 - val_loss: 0.4311 - val_accuracy: 0.8358\n",
      "Epoch 251/300\n",
      "6596/6596 [==============================] - 1s 170us/sample - loss: 0.2047 - accuracy: 0.9134 - val_loss: 0.4241 - val_accuracy: 0.8297\n",
      "Epoch 252/300\n",
      "6596/6596 [==============================] - 1s 168us/sample - loss: 0.2058 - accuracy: 0.9101 - val_loss: 0.4327 - val_accuracy: 0.8212\n",
      "Epoch 253/300\n",
      "6596/6596 [==============================] - 1s 172us/sample - loss: 0.2120 - accuracy: 0.9051 - val_loss: 0.4230 - val_accuracy: 0.8358\n",
      "Epoch 254/300\n",
      "6596/6596 [==============================] - 1s 171us/sample - loss: 0.2094 - accuracy: 0.9078 - val_loss: 0.4307 - val_accuracy: 0.8236\n",
      "Epoch 255/300\n",
      "6596/6596 [==============================] - 1s 172us/sample - loss: 0.2244 - accuracy: 0.9039 - val_loss: 0.4362 - val_accuracy: 0.8273\n",
      "Epoch 256/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2113 - accuracy: 0.9077 - val_loss: 0.4449 - val_accuracy: 0.8285\n",
      "Epoch 257/300\n",
      "6596/6596 [==============================] - 1s 173us/sample - loss: 0.2041 - accuracy: 0.9113 - val_loss: 0.4245 - val_accuracy: 0.8315\n",
      "Epoch 258/300\n",
      "6596/6596 [==============================] - 1s 177us/sample - loss: 0.2052 - accuracy: 0.9113 - val_loss: 0.4371 - val_accuracy: 0.8230\n",
      "Epoch 259/300\n",
      "6596/6596 [==============================] - 1s 166us/sample - loss: 0.2010 - accuracy: 0.9159 - val_loss: 0.4418 - val_accuracy: 0.8188\n",
      "Epoch 260/300\n",
      "6596/6596 [==============================] - 1s 170us/sample - loss: 0.2121 - accuracy: 0.9075 - val_loss: 0.4264 - val_accuracy: 0.8309\n",
      "Epoch 261/300\n",
      "6596/6596 [==============================] - 1s 173us/sample - loss: 0.1992 - accuracy: 0.9122 - val_loss: 0.4253 - val_accuracy: 0.8455\n",
      "Epoch 262/300\n",
      "6596/6596 [==============================] - 1s 177us/sample - loss: 0.2089 - accuracy: 0.9080 - val_loss: 0.4440 - val_accuracy: 0.8194\n",
      "Epoch 263/300\n",
      "6596/6596 [==============================] - 1s 173us/sample - loss: 0.1978 - accuracy: 0.9162 - val_loss: 0.4226 - val_accuracy: 0.8388\n",
      "Epoch 264/300\n",
      "6596/6596 [==============================] - 1s 170us/sample - loss: 0.2034 - accuracy: 0.9118 - val_loss: 0.4255 - val_accuracy: 0.8370\n",
      "Epoch 265/300\n",
      "6596/6596 [==============================] - 1s 170us/sample - loss: 0.2005 - accuracy: 0.9137 - val_loss: 0.4296 - val_accuracy: 0.8376\n",
      "Epoch 266/300\n",
      "6596/6596 [==============================] - 1s 161us/sample - loss: 0.1959 - accuracy: 0.9181 - val_loss: 0.4541 - val_accuracy: 0.8236\n",
      "Epoch 267/300\n",
      "6596/6596 [==============================] - 1s 175us/sample - loss: 0.1995 - accuracy: 0.9154 - val_loss: 0.4245 - val_accuracy: 0.8412\n",
      "Epoch 268/300\n",
      "6596/6596 [==============================] - 1s 168us/sample - loss: 0.1973 - accuracy: 0.9181 - val_loss: 0.4589 - val_accuracy: 0.8236\n",
      "Epoch 269/300\n",
      "6596/6596 [==============================] - 1s 167us/sample - loss: 0.2008 - accuracy: 0.9142 - val_loss: 0.4216 - val_accuracy: 0.8430\n",
      "Epoch 270/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6596/6596 [==============================] - 1s 192us/sample - loss: 0.2007 - accuracy: 0.9119 - val_loss: 0.4524 - val_accuracy: 0.8127\n",
      "Epoch 271/300\n",
      "6596/6596 [==============================] - 1s 177us/sample - loss: 0.1955 - accuracy: 0.9193 - val_loss: 0.4639 - val_accuracy: 0.8194\n",
      "Epoch 272/300\n",
      "6596/6596 [==============================] - 1s 171us/sample - loss: 0.2163 - accuracy: 0.9031 - val_loss: 0.4685 - val_accuracy: 0.8255\n",
      "Epoch 273/300\n",
      "6596/6596 [==============================] - 1s 170us/sample - loss: 0.2001 - accuracy: 0.9116 - val_loss: 0.4537 - val_accuracy: 0.8164\n",
      "Epoch 274/300\n",
      "6596/6596 [==============================] - 1s 172us/sample - loss: 0.1997 - accuracy: 0.9109 - val_loss: 0.4327 - val_accuracy: 0.8291\n",
      "Epoch 275/300\n",
      "6596/6596 [==============================] - 1s 170us/sample - loss: 0.2138 - accuracy: 0.9086 - val_loss: 0.4871 - val_accuracy: 0.8152\n",
      "Epoch 276/300\n",
      "6596/6596 [==============================] - 1s 173us/sample - loss: 0.1978 - accuracy: 0.9143 - val_loss: 0.4407 - val_accuracy: 0.8309\n",
      "Epoch 277/300\n",
      "6596/6596 [==============================] - 1s 173us/sample - loss: 0.1985 - accuracy: 0.9151 - val_loss: 0.4437 - val_accuracy: 0.8273\n",
      "Epoch 278/300\n",
      "6596/6596 [==============================] - 1s 172us/sample - loss: 0.2108 - accuracy: 0.9049 - val_loss: 0.4713 - val_accuracy: 0.8218\n",
      "Epoch 279/300\n",
      "6596/6596 [==============================] - 1s 165us/sample - loss: 0.2197 - accuracy: 0.9001 - val_loss: 0.4351 - val_accuracy: 0.8382\n",
      "Epoch 280/300\n",
      "6596/6596 [==============================] - 1s 167us/sample - loss: 0.1931 - accuracy: 0.9190 - val_loss: 0.4345 - val_accuracy: 0.8388\n",
      "Epoch 281/300\n",
      "6596/6596 [==============================] - 1s 177us/sample - loss: 0.2055 - accuracy: 0.9089 - val_loss: 0.4457 - val_accuracy: 0.8279\n",
      "Epoch 282/300\n",
      "6596/6596 [==============================] - 1s 171us/sample - loss: 0.1982 - accuracy: 0.9175 - val_loss: 0.4589 - val_accuracy: 0.8309\n",
      "Epoch 283/300\n",
      "6596/6596 [==============================] - 1s 165us/sample - loss: 0.1937 - accuracy: 0.9171 - val_loss: 0.4405 - val_accuracy: 0.8267\n",
      "Epoch 284/300\n",
      "6596/6596 [==============================] - 1s 190us/sample - loss: 0.2086 - accuracy: 0.9077 - val_loss: 0.4511 - val_accuracy: 0.8364\n",
      "Epoch 285/300\n",
      "6596/6596 [==============================] - 1s 173us/sample - loss: 0.1903 - accuracy: 0.9186 - val_loss: 0.4525 - val_accuracy: 0.8230\n",
      "Epoch 286/300\n",
      "6596/6596 [==============================] - 1s 165us/sample - loss: 0.2009 - accuracy: 0.9122 - val_loss: 0.4306 - val_accuracy: 0.8424\n",
      "Epoch 287/300\n",
      "6596/6596 [==============================] - 1s 170us/sample - loss: 0.1891 - accuracy: 0.9209 - val_loss: 0.4352 - val_accuracy: 0.8400\n",
      "Epoch 288/300\n",
      "6596/6596 [==============================] - 1s 166us/sample - loss: 0.1990 - accuracy: 0.9149 - val_loss: 0.4432 - val_accuracy: 0.8345\n",
      "Epoch 289/300\n",
      "6596/6596 [==============================] - 1s 163us/sample - loss: 0.2035 - accuracy: 0.9102 - val_loss: 0.4528 - val_accuracy: 0.8261\n",
      "Epoch 290/300\n",
      "6596/6596 [==============================] - 1s 168us/sample - loss: 0.1972 - accuracy: 0.9130 - val_loss: 0.4439 - val_accuracy: 0.8255\n",
      "Epoch 291/300\n",
      "6596/6596 [==============================] - 1s 168us/sample - loss: 0.1984 - accuracy: 0.9137 - val_loss: 0.4554 - val_accuracy: 0.8303\n",
      "Epoch 292/300\n",
      "6596/6596 [==============================] - 1s 168us/sample - loss: 0.1928 - accuracy: 0.9163 - val_loss: 0.4556 - val_accuracy: 0.8297\n",
      "Epoch 293/300\n",
      "6596/6596 [==============================] - 1s 168us/sample - loss: 0.1978 - accuracy: 0.9127 - val_loss: 0.4498 - val_accuracy: 0.8364\n",
      "Epoch 294/300\n",
      "6596/6596 [==============================] - 1s 165us/sample - loss: 0.1872 - accuracy: 0.9212 - val_loss: 0.4490 - val_accuracy: 0.8297\n",
      "Epoch 295/300\n",
      "6596/6596 [==============================] - 1s 166us/sample - loss: 0.1933 - accuracy: 0.9172 - val_loss: 0.4567 - val_accuracy: 0.8279\n",
      "Epoch 296/300\n",
      "6596/6596 [==============================] - 1s 167us/sample - loss: 0.1877 - accuracy: 0.9234 - val_loss: 0.4770 - val_accuracy: 0.8218\n",
      "Epoch 297/300\n",
      "6596/6596 [==============================] - 1s 165us/sample - loss: 0.2127 - accuracy: 0.9033 - val_loss: 0.4881 - val_accuracy: 0.8145\n",
      "Epoch 298/300\n",
      "6596/6596 [==============================] - 1s 178us/sample - loss: 0.2126 - accuracy: 0.9068 - val_loss: 0.4527 - val_accuracy: 0.8388\n",
      "Epoch 299/300\n",
      "6596/6596 [==============================] - 1s 183us/sample - loss: 0.2016 - accuracy: 0.9142 - val_loss: 0.4454 - val_accuracy: 0.8261\n",
      "Epoch 300/300\n",
      "6596/6596 [==============================] - 1s 182us/sample - loss: 0.1916 - accuracy: 0.9190 - val_loss: 0.4560 - val_accuracy: 0.8370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ac92582a88>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name = \"CNN_{}\".format(int(time.time())) \n",
    "log_dir=\"E:\\\\SnehaWork\\\\AIProject\\\\TF_Logs\\\\{}\".format(Name)\n",
    "cnn = models.Sequential([\n",
    "    layers.Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(26,1)),  \n",
    "    layers.MaxPooling1D(pool_size=3),\n",
    "    \n",
    "    layers.Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=3),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(20, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#cnn.summary()\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=0)\n",
    "\n",
    "cnn.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "cnn.fit(X_sm_train, y_sm_train, validation_data=(X_sm_val,y_sm_val), batch_size=375,epochs=300, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 0s 100us/sample - loss: 0.3814 - accuracy: 0.8515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38143863617399526, 0.851457]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-9badac9c24c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myp_sm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    408\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_distribution_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     batch_size, steps = dist_utils.process_batch_and_step_size(\n\u001b[1;32m--> 410\u001b[1;33m         strategy, x, batch_size, steps, mode)\n\u001b[0m\u001b[0;32m    411\u001b[0m     dist_utils.validate_callbacks(input_callbacks=callbacks,\n\u001b[0;32m    412\u001b[0m                                   optimizer=model.optimizer)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\distribute\\distributed_training_utils.py\u001b[0m in \u001b[0;36mprocess_batch_and_step_size\u001b[1;34m(strategy, inputs, batch_size, steps_per_epoch, mode, validation_split)\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;31m# relax the constraint to consume all the training samples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m     steps_per_epoch, batch_size = get_input_params(\n\u001b[1;32m--> 469\u001b[1;33m         strategy, num_samples, steps_per_epoch, batch_size, mode=mode)\n\u001b[0m\u001b[0;32m    470\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\distribute\\distributed_training_utils.py\u001b[0m in \u001b[0;36mget_input_params\u001b[1;34m(distribution_strategy, num_samples, steps, batch_size, mode)\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[0mglobal_batch_size\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_replicas_in_sync\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mallow_partial_batch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m       \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mglobal_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mglobal_batch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   5880\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5881\u001b[0m             new_data = self._data.astype(\n\u001b[1;32m-> 5882\u001b[1;33m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5883\u001b[0m             )\n\u001b[0;32m   5884\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_astype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_astype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m                     \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m                     \u001b[0mvals1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m                     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[1;31m# TODO(extension)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m             raise ValueError(\n\u001b[1;32m--> 700\u001b[1;33m                 \u001b[1;34m\"Cannot convert non-finite values (NA or inf) to \"\u001b[0m \u001b[1;34m\"integer\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    701\u001b[0m             )\n\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "yp_sm = cnn.predict(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting decimal into 0 and 1\n",
    "y_pred_sm = []\n",
    "for i in yp_sm:\n",
    "    if i>0.5:\n",
    "        y_pred_sm.append(1)\n",
    "    else:\n",
    "        y_pred_sm.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2f65432d0c24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_sm_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_sm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_sm_test,y_pred_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15092), started 7 days, 4:34:10 ago. (Use '!kill 15092' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e886d6eaf3654fa1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e886d6eaf3654fa1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
