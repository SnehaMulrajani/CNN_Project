{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('E:\\SnehaWork\\AIProject\\Dataset\\Customer-Churn.csv')\n",
    "df.columns[df.isnull().any()].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5174 1869\n"
     ]
    }
   ],
   "source": [
    "Churned = df[df.Churn == 'Yes']\n",
    "NonChurned = df[df.Churn == 'No']\n",
    "\n",
    "number_of_Churned = len(Churned)\n",
    "number_of_NonChurned = len(NonChurned)\n",
    "\n",
    "Churned_percentage = round((number_of_Churned / (number_of_Churned + number_of_NonChurned)) * 100, 2)\n",
    "valid_percentage = round((number_of_NonChurned / (number_of_Churned + number_of_NonChurned)) * 100, 2)\n",
    "print(number_of_NonChurned,number_of_Churned)\n",
    "#df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes\n",
    "#count yes and no on base data, train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('customerID',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#error='coerce' ignores the errors. Conversion for all except for error values i.e. empty spaces. \n",
    "#.isnull() gives columns which have empty spaces\n",
    "#shows the data which has TotalCharges as null. Good to drop these\n",
    "df.columns[df.isnull().any()].tolist() \n",
    "df[pd.to_numeric(df.TotalCharges,errors='coerce').isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows with TotalCharges as null\n",
    "\n",
    "df1 = df[df.TotalCharges!=' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df1.TotalCharges = pd.to_numeric(df1.TotalCharges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4263: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  method=method,\n"
     ]
    }
   ],
   "source": [
    "df1.replace('No internet service','No',inplace=True)\n",
    "df1.replace('No phone service','No',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6786: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "#replace Yes/No to 1/0 since ML doesn't understand text\n",
    "\n",
    "yes_no_columns = ['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',\n",
    "                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']\n",
    "\n",
    "for col in yes_no_columns:\n",
    "    df1[col].replace({'Yes': 1,'No': 0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['gender'].replace({'Male':1,'Female':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding for multiclass i.e. InternetService, Contract, PaymentMethod\n",
    "\n",
    "multiclass_col=['InternetService', 'Contract', 'PaymentMethod']\n",
    "df1 = pd.get_dummies(data=df1,columns=multiclass_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the values between 1 and 0 for below\n",
    "cols_to_scale = ['tenure','MonthlyCharges','TotalCharges']\n",
    "\n",
    "#MinMaxScaler scales the data between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df1[cols_to_scale] = scaler.fit_transform(df1[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_col_values(df):\n",
    "    for column in df:\n",
    "        print(f'{column} : {df[column].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender : [0 1]\n",
      "SeniorCitizen : [0 1]\n",
      "Partner : [1 0]\n",
      "Dependents : [0 1]\n",
      "tenure : [0.         0.46478873 0.01408451 0.61971831 0.09859155 0.29577465\n",
      " 0.12676056 0.38028169 0.85915493 0.16901408 0.21126761 0.8028169\n",
      " 0.67605634 0.33802817 0.95774648 0.71830986 0.98591549 0.28169014\n",
      " 0.15492958 0.4084507  0.64788732 1.         0.22535211 0.36619718\n",
      " 0.05633803 0.63380282 0.14084507 0.97183099 0.87323944 0.5915493\n",
      " 0.1971831  0.83098592 0.23943662 0.91549296 0.11267606 0.02816901\n",
      " 0.42253521 0.69014085 0.88732394 0.77464789 0.08450704 0.57746479\n",
      " 0.47887324 0.66197183 0.3943662  0.90140845 0.52112676 0.94366197\n",
      " 0.43661972 0.76056338 0.50704225 0.49295775 0.56338028 0.07042254\n",
      " 0.04225352 0.45070423 0.92957746 0.30985915 0.78873239 0.84507042\n",
      " 0.18309859 0.26760563 0.73239437 0.54929577 0.81690141 0.32394366\n",
      " 0.6056338  0.25352113 0.74647887 0.70422535 0.35211268 0.53521127]\n",
      "PhoneService : [0 1]\n",
      "MultipleLines : [0 1]\n",
      "OnlineSecurity : [0 1]\n",
      "OnlineBackup : [1 0]\n",
      "DeviceProtection : [0 1]\n",
      "TechSupport : [0 1]\n",
      "StreamingTV : [0 1]\n",
      "StreamingMovies : [0 1]\n",
      "PaperlessBilling : [1 0]\n",
      "MonthlyCharges : [0.11542289 0.38507463 0.35422886 ... 0.44626866 0.25820896 0.60149254]\n",
      "TotalCharges : [0.0012751  0.21586661 0.01031041 ... 0.03780868 0.03321025 0.78764136]\n",
      "Churn : [0 1]\n",
      "InternetService_DSL : [1 0]\n",
      "InternetService_Fiber optic : [0 1]\n",
      "InternetService_No : [0 1]\n",
      "Contract_Month-to-month : [1 0]\n",
      "Contract_One year : [0 1]\n",
      "Contract_Two year : [0 1]\n",
      "PaymentMethod_Bank transfer (automatic) : [0 1]\n",
      "PaymentMethod_Credit card (automatic) : [0 1]\n",
      "PaymentMethod_Electronic check : [1 0]\n",
      "PaymentMethod_Mailed check : [0 1]\n"
     ]
    }
   ],
   "source": [
    "print_unique_col_values(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5163\n",
       "1    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop churn \n",
    "x = df1.drop('Churn',axis=1)  #check axis=0/1\n",
    "y = df1['Churn']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(sampling_strategy='minority')\n",
    "X_sm_train, y_sm_train = sm.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-6115665dc4e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#X_train = pd.DataFrame(X_train_oversampled, columns=X_train.columns)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;31m# by definition an array here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mprep_ndarray\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Must pass 2-d input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input"
     ]
    }
   ],
   "source": [
    "X_test = pd.DataFrame(X_test, columns=x.columns)\n",
    "#X_train = pd.DataFrame(X_train_oversampled, columns=X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sm_train = pd.Series(y_sm_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_sm_train, X_sm_val, y_sm_train, y_sm_val = train_test_split(X_sm_train,y_sm_train,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_cols = len(x.columns)\n",
    "num_of_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_sm_train=X_sm_train.values.reshape(X_sm_train.shape[0],num_of_cols, 1).astype('float32') \n",
    "X_test=X_test.reshape(X_test.shape[0],num_of_cols, 1).astype('float32')\n",
    "#X_sm_val=X_sm_val.values.reshape(X_sm_val.shape[0],num_of_cols, 1).astype('float32')\n",
    "\n",
    "#sometimes works as X_val.values.reshape(X_val.shape[0],26, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8246, 26, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sm_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_sm_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1407, 26)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6596 samples, validate on 1650 samples\n",
      "Epoch 1/10\n",
      "6596/6596 [==============================] - 5s 760us/sample - loss: 0.5135 - accuracy: 0.7445 - val_loss: 0.8552 - val_accuracy: 0.5127\n",
      "Epoch 2/10\n",
      "6596/6596 [==============================] - 3s 435us/sample - loss: 0.4732 - accuracy: 0.7699 - val_loss: 0.6834 - val_accuracy: 0.6970\n",
      "Epoch 3/10\n",
      "6596/6596 [==============================] - 3s 426us/sample - loss: 0.4635 - accuracy: 0.7737 - val_loss: 0.6857 - val_accuracy: 0.6582\n",
      "Epoch 4/10\n",
      "6596/6596 [==============================] - 3s 433us/sample - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.6111 - val_accuracy: 0.7079\n",
      "Epoch 5/10\n",
      "6596/6596 [==============================] - 3s 436us/sample - loss: 0.4520 - accuracy: 0.7812 - val_loss: 0.5737 - val_accuracy: 0.7273\n",
      "Epoch 6/10\n",
      "6596/6596 [==============================] - 3s 425us/sample - loss: 0.4484 - accuracy: 0.7811 - val_loss: 0.7197 - val_accuracy: 0.6618\n",
      "Epoch 7/10\n",
      "6596/6596 [==============================] - 3s 435us/sample - loss: 0.4432 - accuracy: 0.7861 - val_loss: 0.5300 - val_accuracy: 0.7576\n",
      "Epoch 8/10\n",
      "6596/6596 [==============================] - 3s 433us/sample - loss: 0.4422 - accuracy: 0.7837 - val_loss: 0.6029 - val_accuracy: 0.6976\n",
      "Epoch 9/10\n",
      "6596/6596 [==============================] - 3s 428us/sample - loss: 0.4331 - accuracy: 0.7899 - val_loss: 0.7368 - val_accuracy: 0.6145\n",
      "Epoch 10/10\n",
      "6596/6596 [==============================] - 3s 433us/sample - loss: 0.4307 - accuracy: 0.7909 - val_loss: 0.4283 - val_accuracy: 0.8158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19253e511c8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name = \"CNN_{}\".format(int(time.time())) \n",
    "log_dir=\"E:\\\\SnehaWork\\\\AIProject\\\\TF_Logs\\\\{}\".format(Name)\n",
    "cnn = models.Sequential([\n",
    "    layers.Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(26,1)),  \n",
    "    layers.MaxPooling1D(pool_size=3),\n",
    "    \n",
    "    layers.Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=3),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(20, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#cnn.summary()\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=0)\n",
    "\n",
    "cnn.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "cnn.fit(X_sm_train, y_sm_train, epochs=10, callbacks=[tb_callback],verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 0s 132us/sample - loss: 0.5632 - accuracy: 0.7001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5631817793625843, 0.7000711]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_pred= cnn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_pred = np.round(yp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.70      0.77      1040\n",
      "           1       0.45      0.71      0.55       367\n",
      "\n",
      "    accuracy                           0.70      1407\n",
      "   macro avg       0.66      0.70      0.66      1407\n",
      "weighted avg       0.76      0.70      0.72      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, yp_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[723, 317],\n",
       "       [105, 262]])>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(labels=y_test,predictions=yp_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
